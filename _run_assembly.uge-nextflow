#!/bin/bash -l

SCRIPT_NAME="$(basename ${0#_} .uge-nextflow)"

# Set profile
# Get node number - <=230 = biolinux, >=231 = rosalind
NODE_NUM=$(echo ${HOSTNAME%%.*} | sed 's/node//1')
if [[ ${NODE_NUM} -ge 231 ]]; then
  HPC='rosalind_hpc'
else
  HPC='aspen_hpc'
fi

module load nextflow
nextflow \
  -log ${OUT}/pipeline_info/nextflow_log.${SCRIPT_NAME}.txt \
  run \
  ${LAB_HOME}/workflows/wf-paired-end-illumina-assembly/main.nf \
  -profile ${HPC} \
  --input ${IN} \
  --outdir ${OUT} \
  -ansi-log false \
  -N ${USER}@cdc.gov \
  -w ${OUT}/.work \
  --blast_db ${LAB_HOME}/.databases/ncbi \
  --kraken1_db /scicomp/reference-pure/kraken/OLD/1.0.0/kraken_db \
  --kraken2_db ${LAB_HOME}/.databases/kraken2 \
  -resume

# Check for errors and add to errors.tsv
# Get nextflow run name
run_name=$(grep "Launching" ${OUT}/pipeline_info/ASM_*.o${SCRIPT_NAME} | cut -d '[' -f 2 | cut -d ']' -f 1)

time_stamp=$(date '+%Y-%b-%d %a %H:%M:%S')

# Read each line from nextflow log, find info, and add to errors.tsv
while read -r line; do
  # If process is already running, clean up error
  if [[ "${line}" =~ ^Unable[[:space:]]to[[:space:]]acquire[[:space:]]lock.* ]]; then
    error="You are trying to resume the execution of an already running pipeline."
    ASM_OUT=$(realpath ${OUT}/pipeline_info/ASM_*.o*)
    echo -e "-\t-\t${error}\t${ASM_OUT}\t${time_stamp}\t${run_name}" >> ${OUT}/pipeline_info/errors.tsv
  else
    # Workflow ran some processes
    sample_name=$(grep "nf-" ${line}/.command.run | cut -d '(' -f 2 | cut -d ')' -f 1)
    process=$(grep "NEXTFLOW TASK" ${line}/.command.run | awk -F ':' '{print $NF}' | cut -d ' ' -f 1)
    error=$(tail -n 1 ${line}/.command.err | sed -e 's/\[[^][]*\] //g')

    # Kraken 2 places "Loading database information... done." in error log
    if [[ ${process} =~ .*READ_CLASSIFY_KRAKEN_TWO$ ]] \
      && [[ "${error}" =~ Loading[[:space:]]database[[:space:]]information.*$ ]]; then
      continue
    fi

    # BBDuk java errors
    if [[ ${process} =~ .*REMOVE_PHIX_BBDUK$ ]] \
      && [[ "${error}" =~ .*at.* ]]; then
      error=$(grep -A1 "java.lang" ${line}/.command.err | head -n 2 | tail -n 1)
      if [[ ! ${error} ]]; then
        continue
      elif [[ ${error} =~ ^Mismatch.* ]]; then
        error=${error}
      else
        error=$(grep "java.lang" ${line}/.command.err | awk -F ': ' '{print $2}')
      fi
    elif [[ ${process} =~ .*REMOVE_PHIX_BBDUK$ ]] \
      && [[ "${error}" =~ "Input is being processed as unpaired" ]]; then
      continue
    fi

    # SPAdes errors - typically ran out of memory
    if [[ ${process} =~ .*ASSEMBLE_CONTIGS_SPADES$ ]]; then
      error="ERROR: SPAdes failed. Did it run out of memory?"
    fi

    # Check if error is from file checks
    if [[ ${error} =~ .+Check[[:space:]]failed$ ]]; then
      get_previous_process_workdir=$(dirname $(grep "ln -s" ${line}/.command.run | grep "work" | awk 'END {print $(NF-1)}' ))
      process=$(grep "nf-" ${get_previous_process_workdir}/.command.run | awk -F 'nf-' '{print $2}' | sed -e 's/_(.*//')
      line="${get_previous_process_workdir}"
    fi

    # If process for sample retried and succeeded, ignore
    if [[ -f "$(ls ${OUT}/pipeline_info/process_logs/${sample_name}.*${process}*.command.out)" ]] \
      && [[ $(cat ${line}/.exitcode) = @(0|71|104|134|137|139|140|143|245|250|255) ]]; then
      continue
    else
      echo -e "${sample_name}\t${process}\t${error}\t${line}\t${time_stamp}\t${run_name}" >> ${OUT}/pipeline_info/errors.tsv
    fi
  fi
done < <(nextflow log ${run_name} -filter 'status == "FAILED"')

# Look for errors from process EXTRACT_16S_BIOPYTHON
biopython_rna_errors=( $(find ${OUT}/.work -type f -name ".command.err" -exec grep -l "ERROR: \['16S ribosomal RNA'\]" '{}' \;) )
if [[ $biopython_rna_errors ]]; then
  for line in ${biopython_rna_errors[@]}; do
    work_dir=$(dirname ${line})
    error=$(tail -n 1 ${line} | sed -e 's/[][]//g' | awk -F '/' '{print $1 $NF}')
    sample_name=$(grep "nf-" ${work_dir}/.command.run | cut -d '(' -f 2 | cut -d ')' -f 1)
    process=$(grep "NEXTFLOW TASK" ${work_dir}/.command.run | awk -F ':' '{print $NF}' | cut -d ' ' -f 1)

    # Append to errors.tsv
    echo -e "${sample_name}\t${process}\t${error}\t${work_dir}\t${time_stamp}\t${run_name}" >> ${OUT}/pipeline_info/errors.tsv
  done
fi

# Parse HPC stdout file for QC check failures
QC_FAILURES=()
while read -r line; do
  QC_FAILURES+=("$line")
done < <(awk '/QC check failed/ {print $(NF-3), "("$NF")"}' ${OUT}/pipeline_info/ASM_*.o${SCRIPT_NAME})

if [[ $QC_FAILURES ]]; then
  # Loop over each QC failure
  for f in "${QC_FAILURES[@]}"; do
    # Get work directory
    short_wd=$(grep "$f" ${OUT}/pipeline_info/ASM_*.o${SCRIPT_NAME} | awk -F '[][]' '{print $2}')
    wd_path=$(realpath ${OUT}/.work/${short_wd}*)

    # Get first error
    error=$(grep "ERROR" ${wd_path}/.command.err | head -n 1 | sed -e 's/\[[^][]*\] //g')

    process=$(grep "NEXTFLOW TASK" ${wd_path}/.command.run | awk -F ':' '{print $NF}' | cut -d ' ' -f 1)
    sample_name=$(echo "$f" | awk -F "[()]" '{print $2}')

    # Append to errors.tsv
    echo -e "${sample_name}\t${process}\t${error}\t${wd_path}\t${time_stamp}\t${run_name}" >> ${OUT}/pipeline_info/errors.tsv
  done
fi

# If errors.tsv found..
if [[ -f "${OUT}/pipeline_info/errors.tsv" ]]; then
  # Add column headers
  sed -i '1i Sample Name\tProcess\tError\tError Directory\tTimestamp\tRun Name' ${OUT}/pipeline_info/errors.tsv

  # Remove duplicate lines and lines that have an empty first column
  awk -F '\t' '!_[$1,$2,$3,$6]++' ${OUT}/pipeline_info/errors.tsv \
    | awk -F '\t' '$1{print $0}' \
    > ${OUT}/pipeline_info/errors_new.tsv

  # Delete original errors.tsv and rename errors_new.tsv
  rm ${OUT}/pipeline_info/errors.tsv

  mv ${OUT}/pipeline_info/errors_new.tsv \
    ${OUT}/pipeline_info/errors.tsv
fi

# Count lines in Summary.GenomeCoverage.tab
if [[ -f "${OUT}/Summaries/Summary.GenomeCoverage.tab" ]]; then
  num_assemblies=$(awk 'END {print NR-1}' "${OUT}/Summaries/Summary.GenomeCoverage.tab")
fi

# E-mail completion status
if [[ -f "${OUT}/Summaries/Summary.GenomeCoverage.tab" ]] \
  && [[ -f "${OUT}/pipeline_info/errors.tsv" ]]; then
  echo -e "Assembly and QA finished on $(date)\n${OUT}" | mail \
  -s "${num_assemblies} assembled $(basename "${OUT}") [HPC]" \
  -S smtp="smtpgw.cdc.gov" \
  -a "${OUT}/Summaries/Summary.GenomeCoverage.tab" \
  -a "${OUT}/pipeline_info/errors.tsv" \
  "${USER}@cdc.gov"

elif [[ -f "${OUT}/Summaries/Summary.GenomeCoverage.tab" ]]; then
  echo -e "Assembly and QA finished on $(date)\n${OUT}" | mail \
  -s "${num_assemblies} assembled $(basename "${OUT}") [HPC]" \
  -S smtp="smtpgw.cdc.gov" \
  -a "${OUT}/Summaries/Summary.GenomeCoverage.tab" \
  "${USER}@cdc.gov"

elif [[ -f "${OUT}/pipeline_info/errors.tsv" ]]; then
  echo -e "Assembly and QA could not be completed on $(date)\n${OUT}" | mail \
  -s "No assemblies found $(basename "${OUT}") [HPC]" \
  -S smtp="smtpgw.cdc.gov" \
  -a "${OUT}/pipeline_info/errors.tsv" \
  "${USER}@cdc.gov"
fi

# Move and symlink work directory
# date=$(date '+%Y-%m-%d_%H-%M-%S')
# mv ${OUT}/.work /scicomp/scratch/${USER}/work/ASM_${date}
# ln -s /scicomp/scratch/${USER}/work/ASM_${date} ${OUT}/.work
